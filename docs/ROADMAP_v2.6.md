# Voice Soundboard v2.6 Roadmap

**Target**: Q2 2027  
**Theme**: "Accessibility & Inclusive Audio"

---

## Executive Summary

v2.6 makes Voice Soundboard fully accessible, ensuring synthesized audio works for everyone:

1. **Screen Reader Integration** ‚Äî Native support for NVDA, JAWS, VoiceOver
2. **Visual Accessibility** ‚Äî Audio descriptions, navigation cues, non-visual feedback
3. **Hearing Accessibility** ‚Äî Real-time captions, transcripts, visual waveforms
4. **Motor Accessibility** ‚Äî Voice commands, switch control, reduced interaction
5. **Cognitive Accessibility** ‚Äî Plain language modes, predictable patterns
6. **Developer Accessibility** ‚Äî Accessible docs, tooling, and testing

No breaking changes. Fully backwards compatible with v2.5.

---

## üéØ Primary Goals

### 1. Screen Reader Integration (P0)

**Status**: Design phase  
**Effort**: Large  
**Risk**: Medium

First-class support for screen readers and assistive technologies.

#### Architecture

```
VoiceEngine ‚Üí AccessibilityBridge ‚Üí Screen Reader
                    ‚Üì
              ARIA Live Regions (web)
                    ‚Üì
              AT-SPI / UIA (native)
```

#### Key Components

| Component | Description | Status |
|-----------|-------------|--------|
| `AccessibilityBridge` | Universal AT connector | üî≤ Design |
| `ScreenReaderAdapter` | NVDA/JAWS/VoiceOver support | üî≤ Design |
| `LiveRegionManager` | ARIA live region control | üî≤ Design |
| `FocusManager` | Audio focus and interruption | üî≤ Design |
| `AnnouncementQueue` | Ordered announcements | üî≤ Design |

#### API (Proposed)

```python
from voice_soundboard.accessibility import (
    AccessibilityBridge,
    ScreenReaderMode,
    Announcement,
)

# Initialize accessibility
bridge = AccessibilityBridge(
    screen_reader=ScreenReaderMode.AUTO,  # Auto-detect
    announce_progress=True,
    interrupt_policy="polite",  # polite, assertive, off
)

# Connect to engine
engine = VoiceEngine(Config(accessibility=bridge))

# Synthesis with screen reader awareness
result = engine.speak("Welcome to the application!")

# Screen reader hears: "Voice Soundboard: Welcome to the application!"
# Configurable prefix/suffix for clarity

# Manual announcements
bridge.announce(
    Announcement(
        text="Processing complete",
        priority="polite",
        clear_queue=False,
    )
)

# Progress announcements for long operations
async for chunk in engine.stream("Long text..."):
    # Periodic: "25% complete... 50% complete..."
    pass
```

#### Screen Reader Specific Features

```python
# NVDA add-on integration
from voice_soundboard.accessibility.nvda import NVDABridge

nvda = NVDABridge()
nvda.register_gesture("kb:NVDA+shift+v", engine.speak_clipboard)

# VoiceOver (macOS/iOS)
from voice_soundboard.accessibility.voiceover import VoiceOverBridge

vo = VoiceOverBridge()
vo.set_audio_ducking(True)  # Duck VoiceOver during playback

# JAWS scripting
from voice_soundboard.accessibility.jaws import JAWSBridge

jaws = JAWSBridge()
jaws.register_hotkey("Control+Shift+S", engine.speak_selection)
```

#### Success Criteria

- [ ] NVDA, JAWS, VoiceOver, Narrator all supported
- [ ] Zero conflicts with screen reader speech
- [ ] Proper audio ducking and focus management
- [ ] All operations announced appropriately

---

### 2. Audio Description System (P0)

**Status**: Design phase  
**Effort**: Large  
**Risk**: Low

Generate and manage audio descriptions for visual content.

#### 2.1 Description Generation

```python
from voice_soundboard.accessibility import AudioDescriber

describer = AudioDescriber(
    voice="af_bella",
    style="descriptive",  # descriptive, concise, extended
    timing="auto",  # Fit descriptions into natural pauses
)

# Describe images
description = describer.describe_image("chart.png")
# "A bar chart showing quarterly sales. Q1 at 50 thousand, 
#  Q2 rising to 75 thousand, Q3 at 60 thousand, Q4 highest at 90 thousand."

# Describe video (frame analysis)
descriptions = describer.describe_video(
    "presentation.mp4",
    interval_seconds=5.0,
    skip_when_speech=True,
)
```

#### 2.2 Description Tracks

```python
from voice_soundboard.accessibility import DescriptionTrack

# Create description track for existing audio
track = DescriptionTrack()

track.add(timestamp=0.0, text="A woman enters a busy caf√©")
track.add(timestamp=5.2, text="She approaches the counter")
track.add(timestamp=12.0, text="The barista smiles and waves")

# Mix with original audio
mixed = track.mix_with(
    original_audio,
    engine,
    duck_original=0.3,  # Reduce original volume during descriptions
)
```

#### 2.3 Real-time Description

```python
from voice_soundboard.accessibility import LiveDescriber

# For live events, video calls, etc.
describer = LiveDescriber(
    engine=engine,
    latency_ms=500,
    buffer_descriptions=True,
)

# Connect to video stream
describer.connect(video_stream)

# Descriptions generated and spoken in real-time
async for description in describer.stream():
    print(f"Describing: {description.text}")
```

---

### 3. Caption & Transcript System (P1)

**Status**: Design phase  
**Effort**: Medium  
**Risk**: Low

Real-time captions and synchronized transcripts for hearing accessibility.

#### 3.1 Caption Generation

```python
from voice_soundboard.accessibility import CaptionGenerator

captions = CaptionGenerator(
    format="webvtt",  # webvtt, srt, ttml
    max_line_length=42,
    max_lines=2,
    position="bottom",
)

# Generate captions from synthesis
result = engine.speak("Hello, welcome to our presentation.")
caption_file = captions.generate(result)

# Output (WebVTT):
# WEBVTT
#
# 00:00:00.000 --> 00:00:02.500
# Hello, welcome to our presentation.
```

#### 3.2 Live Captions

```python
from voice_soundboard.accessibility import LiveCaptions

# Real-time caption display
captions = LiveCaptions(
    display="overlay",  # overlay, sidebar, external
    font_size="large",
    background_opacity=0.8,
    speaker_labels=True,
)

# Stream with live captions
async for chunk in engine.stream(text):
    caption = captions.update(chunk)
    # Caption updates in real-time on screen
```

#### 3.3 Transcript Export

```python
from voice_soundboard.accessibility import TranscriptExporter

exporter = TranscriptExporter(
    include_timestamps=True,
    include_speakers=True,
    format="markdown",  # markdown, html, docx, txt
)

# Export conversation transcript
transcript = exporter.export(conversation)

# Output:
# ## Transcript
# 
# **[00:00]** **Alice:** Hello Bob!
# **[00:02]** **Bob:** Hi Alice, how are you?
```

---

## üîß Secondary Goals

### 4. Motor Accessibility (P2)

#### 4.1 Voice Command Interface

```python
from voice_soundboard.accessibility import VoiceCommands

commands = VoiceCommands(
    wake_word=None,  # Always listening (or set wake word)
    language="en-US",
    confirmation_mode="audio",  # audio, visual, both
)

# Register commands
commands.register("speak this", lambda: engine.speak(clipboard.get()))
commands.register("stop", engine.stop)
commands.register("repeat", engine.repeat_last)
commands.register("slower", lambda: engine.set_speed(0.8))
commands.register("faster", lambda: engine.set_speed(1.2))

# Custom commands
@commands.command("read {filename}")
def read_file(filename: str):
    with open(filename) as f:
        engine.speak(f.read())
```

#### 4.2 Switch Control Support

```python
from voice_soundboard.accessibility import SwitchControl

# Single-switch scanning interface
switch = SwitchControl(
    scan_speed_ms=1500,
    auto_scan=True,
    actions=[
        "Play/Pause",
        "Skip Forward",
        "Skip Back", 
        "Volume Up",
        "Volume Down",
        "Menu",
    ],
)

# Two-switch mode
switch = SwitchControl(
    mode="two_switch",  # Switch 1: scan, Switch 2: select
)

# Hook into engine
engine = VoiceEngine(Config(switch_control=switch))
```

#### 4.3 Reduced Interaction Mode

```python
from voice_soundboard.accessibility import ReducedInteraction

# Minimize required user actions
reduced = ReducedInteraction(
    auto_play=True,
    auto_advance=True,
    pause_on_focus_loss=False,
    large_targets=True,  # For limited motor control
    dwell_click_ms=1000,  # Hover to activate
)

engine = VoiceEngine(Config(reduced_interaction=reduced))
```

---

### 5. Visual Feedback System (P2)

#### 5.1 Waveform Visualization

```python
from voice_soundboard.accessibility import WaveformVisualizer

visualizer = WaveformVisualizer(
    style="waveform",  # waveform, spectrogram, bars
    color_scheme="high_contrast",
    show_amplitude=True,
    show_frequency=False,
)

# Real-time visualization during playback
visualizer.attach(engine)

# Export static visualization
image = visualizer.render(result.audio, width=800, height=200)
image.save("waveform.png")
```

#### 5.2 Visual Speech Indicators

```python
from voice_soundboard.accessibility import SpeechIndicator

# Visual feedback during synthesis
indicator = SpeechIndicator(
    style="pulsing_circle",  # pulsing_circle, bouncing_bars, text_highlight
    sync_to_words=True,
    color_by_speaker=True,
)

# Shows visual indication of who's speaking
indicator.attach(conversation)
```

#### 5.3 Haptic Feedback

```python
from voice_soundboard.accessibility import HapticFeedback

haptics = HapticFeedback(
    device="controller",  # controller, phone, wearable
    patterns={
        "word_boundary": "tap",
        "sentence_end": "double_tap",
        "speaker_change": "buzz",
        "emphasis": "pulse",
    },
)

# Haptic feedback synced to speech
engine = VoiceEngine(Config(haptics=haptics))
```

---

### 6. Cognitive Accessibility (P2)

#### 6.1 Plain Language Mode

```python
from voice_soundboard.accessibility import PlainLanguage

simplifier = PlainLanguage(
    reading_level="grade_6",  # grade_3 to grade_12
    avoid_jargon=True,
    short_sentences=True,
    define_terms=True,
)

text = "The API utilizes asynchronous paradigms for optimal throughput."
simple = simplifier.transform(text)
# "The program works on multiple tasks at once to run faster."

# Auto-simplify during synthesis
engine = VoiceEngine(Config(plain_language=simplifier))
```

#### 6.2 Reading Assistance

```python
from voice_soundboard.accessibility import ReadingAssistant

assistant = ReadingAssistant(
    highlight_current_word=True,
    highlight_current_sentence=True,
    word_spacing="wide",
    line_spacing=1.8,
    font="OpenDyslexic",
)

# Synchronized text display with audio
display = assistant.create_display(text)
display.sync_with(engine)

# Dyslexia-friendly features
assistant.enable_ruler()  # Reading ruler
assistant.enable_syllable_breaks()  # Hy-phen-ate words
```

#### 6.3 Predictable Patterns

```python
from voice_soundboard.accessibility import ConsistencyGuard

guard = ConsistencyGuard(
    announce_changes=True,
    confirm_destructive=True,
    consistent_navigation=True,
    timeout_warnings=True,
)

# All operations follow predictable patterns
engine = VoiceEngine(Config(consistency=guard))

# User always knows:
# - What will happen before it happens
# - When something has changed
# - How to undo/cancel
```

---

### 7. Navigation & Orientation (P2)

#### 7.1 Audio Landmarks

```python
from voice_soundboard.accessibility import AudioLandmarks

landmarks = AudioLandmarks(
    earcons={
        "section_start": "chime_up.wav",
        "section_end": "chime_down.wav",
        "heading": "ding.wav",
        "list_start": "list_start.wav",
        "link": "click.wav",
    },
    announce_structure=True,
)

# Navigate content by structure
engine = VoiceEngine(Config(landmarks=landmarks))

# Users can:
# - Jump to next/previous heading
# - Skip to next section
# - Navigate by paragraph
# - Jump to specific speakers
```

#### 7.2 Audio Table Navigation

```python
from voice_soundboard.accessibility import TableNavigator

nav = TableNavigator(
    announce_position=True,  # "Row 3, Column 2"
    announce_headers=True,   # "Name: John"
    wrap_navigation=True,
)

# Make tables accessible
table_data = [
    ["Name", "Age", "City"],
    ["Alice", "30", "NYC"],
    ["Bob", "25", "LA"],
]

audio = nav.read_table(table_data, engine)

# Keyboard navigation:
# Arrow keys: cell by cell
# Ctrl+Arrow: row/column jump
# H: read column header
```

#### 7.3 Document Structure

```python
from voice_soundboard.accessibility import DocumentStructure

structure = DocumentStructure()

# Parse document structure
doc = structure.parse("report.html")

# Navigate by headings
headings = doc.get_headings()
for h in headings:
    print(f"Level {h.level}: {h.text}")

# Jump to section
section = doc.get_section("Conclusion")
engine.speak(section.content)

# Table of contents as audio
toc = doc.generate_toc()
engine.speak(toc, voice="narrator")
```

---

### 8. Accessibility Testing (P3)

#### 8.1 Automated Testing

```python
from voice_soundboard.accessibility.testing import AccessibilityAuditor

auditor = AccessibilityAuditor(
    standards=["WCAG_2.1_AA", "Section_508"],
    checks=[
        "contrast_ratio",
        "caption_accuracy",
        "timing_adjustable",
        "keyboard_accessible",
        "screen_reader_compatible",
    ],
)

# Audit synthesis output
report = auditor.audit(result)

# Report:
# ‚úÖ Captions synchronized (¬±50ms)
# ‚úÖ Playback controls keyboard accessible
# ‚ö†Ô∏è No pause between speakers (recommendation)
# ‚ùå Missing audio description for visual content
```

#### 8.2 Screen Reader Testing

```python
from voice_soundboard.accessibility.testing import ScreenReaderTest

# Automated screen reader testing
test = ScreenReaderTest(
    screen_reader="nvda",  # nvda, jaws, voiceover
    headless=True,
)

# Verify announcements
with test.session() as sr:
    engine.speak("Hello world")
    
    assert sr.heard("Voice Soundboard")
    assert sr.heard("Hello world")
    assert not sr.heard_overlap()  # No speech collision
```

#### 8.3 User Testing Support

```python
from voice_soundboard.accessibility.testing import UserTestSession

# Record accessibility user testing sessions
session = UserTestSession(
    record_audio=True,
    record_interactions=True,
    record_screen_reader=True,
)

with session.start() as test:
    # User performs tasks
    test.mark_task("Navigate to settings")
    # ... user actions ...
    test.mark_complete(success=True, time_seconds=15)
    
# Generate report
report = session.generate_report()
# Includes timing, success rates, pain points
```

---

### 9. Internationalization Accessibility (P3)

#### 9.1 Multi-language Screen Reader

```python
from voice_soundboard.accessibility import MultiLanguageAT

# Handle mixed-language content accessibly
ml = MultiLanguageAT(
    primary_language="en",
    announce_language_changes=True,
    fallback_voice="auto",
)

text = "Hello! Bonjour! Hola!"
# Announces: "English: Hello! French: Bonjour! Spanish: Hola!"

engine = VoiceEngine(Config(multilang_at=ml))
```

#### 9.2 RTL Language Support

```python
from voice_soundboard.accessibility import RTLSupport

rtl = RTLSupport(
    visual_mirroring=True,
    reading_direction="auto",
    bidirectional_text=True,
)

# Properly handle Hebrew, Arabic, etc.
engine = VoiceEngine(Config(rtl=rtl))
engine.speak("◊©◊ú◊ï◊ù Hello ŸÖÿ±ÿ≠ÿ®ÿß")  # Mixed RTL/LTR
```

---

## üìÖ Timeline

```
2027-01-01  v2.6 design review
     ‚îÇ      - Accessibility architecture RFC
     ‚îÇ      - Screen reader integration spec
     ‚îÇ      - User research with disability community
     ‚îÇ
     ‚ñº
2027-02-01  v2.6-alpha.1
     ‚îÇ      - AccessibilityBridge core
     ‚îÇ      - NVDA integration
     ‚îÇ      - Caption generation
     ‚îÇ
     ‚ñº
2027-03-01  v2.6-alpha.2
     ‚îÇ      - VoiceOver support
     ‚îÇ      - Audio descriptions
     ‚îÇ      - Voice commands
     ‚îÇ
     ‚ñº
2027-04-01  v2.6-beta.1
     ‚îÇ      - JAWS integration
     ‚îÇ      - Cognitive accessibility
     ‚îÇ      - Visual feedback system
     ‚îÇ
     ‚ñº
2027-05-01  v2.6-rc.1
     ‚îÇ      - Feature freeze
     ‚îÇ      - Accessibility audit (external)
     ‚îÇ      - User testing with disability community
     ‚îÇ
     ‚ñº
2027-06-01  v2.6.0 release
```

---

## üìã Full Feature Matrix

| Feature | Priority | Effort | Status |
|---------|----------|--------|--------|
| AccessibilityBridge core | P0 | Large | üî≤ Design |
| NVDA integration | P0 | Medium | üî≤ Design |
| VoiceOver integration | P0 | Medium | üî≤ Design |
| JAWS integration | P0 | Medium | üî≤ Design |
| Windows Narrator support | P0 | Small | üî≤ Design |
| Audio descriptions | P0 | Large | üî≤ Design |
| Caption generation | P1 | Medium | üî≤ Design |
| Live captions | P1 | Medium | üî≤ Design |
| Transcript export | P1 | Small | üî≤ Design |
| Voice commands | P2 | Medium | üî≤ Design |
| Switch control | P2 | Medium | üî≤ Design |
| Waveform visualization | P2 | Small | üî≤ Design |
| Haptic feedback | P2 | Medium | üî≤ Research |
| Plain language mode | P2 | Medium | üî≤ Design |
| Reading assistant | P2 | Medium | üî≤ Design |
| Audio landmarks | P2 | Small | üî≤ Design |
| Table navigation | P2 | Medium | üî≤ Design |
| Accessibility auditor | P3 | Medium | üî≤ Design |
| Screen reader testing | P3 | Large | üî≤ Design |
| Multi-language AT | P3 | Medium | üî≤ Design |
| RTL support | P3 | Small | üî≤ Design |

---

## üö´ Explicitly NOT in v2.6

These remain for future versions:

- ‚ùå Built-in OCR (use external libraries)
- ‚ùå Sign language avatar generation
- ‚ùå Real-time speech-to-text (STT)
- ‚ùå Braille display output
- ‚ùå Eye tracking support
- ‚ùå Breaking API changes

---

## üéØ Success Metrics

### Screen Reader Compatibility
- 100% feature parity across NVDA, JAWS, VoiceOver
- Zero speech collisions or interruptions
- < 100ms announcement latency

### Caption Accuracy
- > 99% word accuracy in captions
- ‚â§ 50ms caption synchronization
- Support for all 40+ voices

### User Satisfaction
- > 90% satisfaction from users with disabilities
- Accessibility audit: WCAG 2.1 AA compliant
- Section 508 compliant for government use

### Developer Experience
- Accessibility testing: < 5 lines to add
- Documentation available in accessible formats
- All examples accessible by default

---

## üîÑ Migration from v2.5

### No Breaking Changes

v2.6 is fully backwards compatible. Existing code works unchanged.

### New Optional Features

```python
# v2.5 code (still works)
engine = VoiceEngine()
result = engine.speak("Hello!")

# v2.6 enhancements (opt-in)
from voice_soundboard.accessibility import AccessibilityBridge

engine = VoiceEngine(Config(
    accessibility=AccessibilityBridge(),  # New: AT support
    captions=True,                        # New: auto-captions
    announce_progress=True,               # New: progress for AT
))
```

### Accessibility by Default

Starting v2.6, some accessibility features are enabled by default:

```python
# These are now automatic:
# - Screen reader detection
# - Keyboard navigation
# - High contrast support in visualizations
# - ARIA attributes in web output

# Disable if needed (not recommended):
engine = VoiceEngine(Config(accessibility=None))
```

---

## üìù How to Contribute

1. **User Research**: Participate in accessibility testing sessions
2. **Screen Reader Expertise**: Help with NVDA/JAWS/VoiceOver integration
3. **Accessibility Auditing**: Review features against WCAG standards
4. **Documentation**: Help make docs accessible (alt text, structure)
5. **Translations**: Translate accessibility documentation

---

## Appendix A: WCAG 2.1 Compliance Matrix

| Criterion | Level | Voice Soundboard Support |
|-----------|-------|-------------------------|
| 1.1.1 Non-text Content | A | ‚úÖ Audio descriptions |
| 1.2.1 Audio-only Content | A | ‚úÖ Transcripts |
| 1.2.2 Captions | A | ‚úÖ Live & pre-recorded |
| 1.2.3 Audio Description | A | ‚úÖ Description tracks |
| 1.2.5 Audio Description (Extended) | AA | ‚úÖ Extended descriptions |
| 1.4.2 Audio Control | A | ‚úÖ Pause, stop, volume |
| 2.1.1 Keyboard | A | ‚úÖ Full keyboard support |
| 2.2.1 Timing Adjustable | A | ‚úÖ Speed control |
| 2.2.2 Pause, Stop, Hide | A | ‚úÖ Playback controls |
| 3.1.1 Language of Page | A | ‚úÖ Language detection |
| 4.1.2 Name, Role, Value | A | ‚úÖ ARIA support |

---

## Appendix B: Screen Reader Interaction Model

### Announcement Priority Levels

| Priority | Use Case | Behavior |
|----------|----------|----------|
| `assertive` | Errors, critical alerts | Interrupts current speech |
| `polite` | Status updates, progress | Queued after current |
| `off` | Decorative, non-essential | Not announced |

### Audio Focus Management

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Audio Focus Stack             ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ 1. Screen Reader (highest priority)     ‚îÇ
‚îÇ 2. System Alerts                        ‚îÇ
‚îÇ 3. Voice Soundboard Output              ‚îÇ
‚îÇ 4. Background Audio (ducked)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

When Voice Soundboard plays:
- Screen reader speech completes first (polite)
- OR screen reader ducks (assertive with ducking)
- Background audio reduces volume
```

---

## Appendix C: Accessibility Testing Checklist

### Before Release (Manual)

- [ ] Navigate entire interface with keyboard only
- [ ] Complete all tasks with screen reader (NVDA)
- [ ] Complete all tasks with screen reader (VoiceOver)
- [ ] Verify color contrast ratios (4.5:1 minimum)
- [ ] Test with browser zoom at 200%
- [ ] Verify captions match audio content
- [ ] Test with voice commands only
- [ ] Verify haptic feedback (mobile)

### Automated (CI/CD)

```yaml
# .github/workflows/accessibility.yml
accessibility-tests:
  runs-on: ubuntu-latest
  steps:
    - uses: actions/checkout@v4
    - name: Run accessibility auditor
      run: |
        python -m pytest tests/accessibility/ -v
        python -m voice_soundboard.accessibility.audit --standard WCAG_2.1_AA
```

---

*Last updated: 2026-02-07*
